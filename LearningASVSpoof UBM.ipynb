{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.mixture import GMM\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "import itertools\n",
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mfcc_original_train = np.loadtxt('mfcc_original_train.txt')\n",
    "\n",
    "mfcc_spoof_train = np.loadtxt('mfcc_spoof_train.txt')\n",
    "\n",
    "mfcc_original_develop = np.loadtxt('mfcc_original_dev.txt')\n",
    "\n",
    "mfcc_spoof_develop = np.loadtxt('mfcc_spoof_dev.txt')\n",
    "\n",
    "mfcc_original_test = np.loadtxt('mfcc_original_eva.txt')\n",
    "\n",
    "mfcc_spoof_test = np.loadtxt('mfcc_spoof_eva.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mfcc_original_train = np.loadtxt('N:\\Science\\Antispoofing Research (ipython notebook)\\gmm t-sne\\mfcc_all\\mfcc_train_human.txt')\n",
    "\n",
    "mfcc_spoof_train = np.loadtxt('N:\\Science\\Antispoofing Research (ipython notebook)\\gmm t-sne\\mfcc_all\\mfcc_spoof_train.txt')\n",
    "\n",
    "mfcc_original_develop = np.loadtxt('N:\\Science\\Antispoofing Research (ipython notebook)\\gmm t-sne\\mfcc_all\\mfcc_dev_human.txt')\n",
    "\n",
    "mfcc_spoof_develop = np.loadtxt('N:\\Science\\Antispoofing Research (ipython notebook)\\gmm t-sne\\mfcc_all\\mfcc_spoof_dev.txt')\n",
    "\n",
    "mfcc_original_test = np.loadtxt('N:\\Science\\Antispoofing Research (ipython notebook)\\gmm t-sne\\mfcc_all\\mfcc_eva_human.txt')\n",
    "\n",
    "mfcc_spoof_test = np.loadtxt('N:\\Science\\Antispoofing Research (ipython notebook)\\gmm t-sne\\mfcc_all\\mfcc_spoof_eva.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.concatenate([mfcc_original_train, mfcc_spoof_train]) \n",
    "y_train = np.concatenate([np.zeros((mfcc_original_train.shape[0])), np.ones((mfcc_spoof_train.shape[0]))]).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_develop = np.concatenate([mfcc_original_develop, mfcc_spoof_develop]) \n",
    "y_develop = np.concatenate([np.zeros((mfcc_original_develop.shape[0])), np.ones((mfcc_spoof_develop.shape[0]))]).astype('int')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = np.concatenate([mfcc_original_test, mfcc_spoof_test]) \n",
    "y_test = np.concatenate([np.zeros((mfcc_original_test.shape[0])), np.ones((mfcc_spoof_test.shape[0]))]).astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeUBM(ubm_model, data):\n",
    "    ###########################################\n",
    "    # ubm_model - gmm-represent distribution of our model\n",
    "    # data - samples, which will correct ubm-model\n",
    "    ###############################################\n",
    "\n",
    "    xdim = data.shape[1]\n",
    "    M = ubm_model.n_components\n",
    "\n",
    "    ###############################################################\n",
    "    #    ubm_means: means of the ubm <number array>               #\n",
    "    #    ubm_covars: covariances of the ubm <number array>        #\n",
    "    #    ubm_weights: weights of the ubm <number array>           #\n",
    "    #    new_means: means adapted from the ubm <number array>     #\n",
    "    #    new_weights: weights adapted from the ubm <number array> #\n",
    "    ###############################################################\n",
    "\n",
    "    # Copy parameters GMM-model\n",
    "    ubm_weights = ubm_model.weights_\n",
    "    ubm_means = ubm_model.means_\n",
    "    ubm_covars = ubm_model.covars_\n",
    "\n",
    "    ###################################################################\n",
    "    # for X = {x_1, ..., x_T}                                         #\n",
    "    # P(i|x_t) = w_i * p_i(x_t) / sum_j=1_M(w_j * P_j(x_t))           #\n",
    "    ###################################################################\n",
    "\n",
    "    posterior_prob = ubm_model.predict_proba(data)\n",
    "    pr_i_xt = (ubm_weights * posterior_prob) / np.asmatrix(np.sum(ubm_weights \\\n",
    "                                                                  * posterior_prob, axis=1)).T\n",
    "\n",
    "    n_i = np.asarray(np.sum(pr_i_xt, axis=0)).flatten()  # [M, ]\n",
    "\n",
    "    # Then we can compute E(x) and E(x2) and calculate new parameters of\n",
    "    # our model\n",
    "\n",
    "    E_x = np.asarray([(np.asarray(pr_i_xt[:, i]) * data).sum(axis=0) / n_i[i] if not n_i[i] == 0. else np.zeros(xdim) for i in range(M)])  # [M x xdim]\n",
    "    E_x2 = np.asarray([(np.asarray(pr_i_xt[:, i]) * (data ** 2)).sum(axis=0) / n_i[i]  if not n_i[i] == 0. else np.zeros(xdim)for i in range(M)])  # [M x xdim]\n",
    "\n",
    "    ################################################################\n",
    "    #    T: scaling factor, number of samples                      #\n",
    "    #    relevance_factor: factor for scaling the adapted means    #\n",
    "    #    scaleparam - scale parameter for weights matrix estimation#\n",
    "    ################################################################\n",
    "\n",
    "    T = data.shape[0]\n",
    "    relevance_factor = 16\n",
    "    scaleparam = 1\n",
    "\n",
    "    ################################################################\n",
    "    # compute alpha_i: data-depentend apaptation coefficient       #\n",
    "    # alpha_w = alpha_m = alpha_v                                  #\n",
    "    # alpha_i = n_i/ (n_i + relevance factor)                      #\n",
    "    ################################################################\n",
    "\n",
    "    alpha_i = n_i / (n_i + relevance_factor)\n",
    "\n",
    "    ###############################\n",
    "    # Parqameter`s adaptation\n",
    "    ##############################\n",
    "    new_weights = (alpha_i * n_i / T + (1.0 - alpha_i) * ubm_weights) * scaleparam\n",
    "\n",
    "    alpha_i = np.asarray(np.asmatrix(alpha_i).T)\n",
    "    new_means = (alpha_i * E_x + (1. - alpha_i) * ubm_means)\n",
    "    new_covars = alpha_i * E_x2 + (1. - alpha_i) * (ubm_covars + (ubm_means ** 2)) - (new_means ** 2)\n",
    "\n",
    "    #############################################\n",
    "    # if we want compute `full` covariance matrix - comment code here\n",
    "    # new_covars = np.zeros([M, xdim, xdim])\n",
    "    # for j in range(M):\n",
    "    #    new_covars[j] = alpha_i[j]*E_x2[j] +(1. - alpha_i[j]).flatten()*(ubm_covars[j] + (new_means[j]**2))- (ubm_means[j]**2)\n",
    "    #    new_covars[i] = np.where(new_covars[i] < MIN_VARIANCE, MIN_VARIANCE, new_covars[i])\n",
    "    ####################################################################\n",
    "    #   `covars_` : array\n",
    "    #    Covariance parameters for each mixture component.  The shape\n",
    "    #    depends on `covariance_type`::\n",
    "    #        (n_components, n_features)             if 'spherical',\n",
    "    #        (n_features, n_features)               if 'tied',\n",
    "    #        (n_components, n_features)             if 'diag',\n",
    "    #        (n_components, n_features, n_features) if 'full'\n",
    "    #####################################################################\n",
    "\n",
    "    ubm_model.means_ = new_means\n",
    "    ubm_model.weights_ = new_weights\n",
    "    ubm_model.covars_ = new_covars\n",
    "\n",
    "    return ubm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy - prediction on development set 77.3064528217\n"
     ]
    }
   ],
   "source": [
    "n_g = 1024\n",
    "g1 =  GMM(n_components = n_g, covariance_type='diag',init_params='wmc', n_iter=20)\n",
    "g1.fit(mfcc_original_train)\n",
    "\n",
    "g2 =  GMM(n_components = n_g, covariance_type='diag',init_params='wmc', n_iter=20)\n",
    "g2.fit(mfcc_spoof_train)\n",
    "\n",
    "prediction  = np.array(np.log(mfcc_original_train.shape[0])+ g1.score(X_develop)  < np.log(mfcc_spoof_train.shape[0])+g2.score(X_develop)).astype('int')\n",
    "\n",
    "accuracy = np.mean(prediction == y_develop) * 100\n",
    "print 'accuracy - prediction on development set', accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy - prediction on evaluation set 73.2154693607\n"
     ]
    }
   ],
   "source": [
    "prediction  = np.array(np.log(mfcc_original_train.shape[0])+ g1.score(X_test)  < np.log(mfcc_spoof_train.shape[0])+g2.score(X_test)).astype('int')\n",
    "\n",
    "accuracy = np.mean(prediction == y_test) * 100\n",
    "print 'accuracy - prediction on evaluation set', accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_adapt = computeUBM(g1, mfcc_original_develop)\n",
    "g2_adapt = computeUBM(g2, mfcc_spoof_develop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy - prediction on evaluation set. adapted on development 83.0072455487\n"
     ]
    }
   ],
   "source": [
    "prediction  = np.array(np.log(mfcc_original_train.shape[0])+ g1_adapt.score(X_test)  < np.log(mfcc_spoof_train.shape[0])+g2_adapt.score(X_test)).astype('int')\n",
    "accuracy = np.mean(prediction == y_test) * 100\n",
    "print 'accuracy - prediction on evaluation set. adapted on development', accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5311  18163]\n",
      " [  4093 165837]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(prediction, y_test)\n",
    "print cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.5835453248\n",
      "84.4046658807\n",
      "84.2438625882\n",
      "84.0804740336\n",
      "84.0220471138\n",
      "84.0065355422\n",
      "84.3788132614\n",
      "84.8426092532\n",
      "85.1073400757\n",
      "85.5835453248\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(1,10):\n",
    "    g1_adapt = computeUBM(g1_adapt, mfcc_original_develop)\n",
    "    g2_adapt = computeUBM(g2_adapt, mfcc_spoof_develop)\n",
    "    \n",
    "    prediction  = np.array(np.log(mfcc_original_train.shape[0])+ g1_adapt.score(X_test)  < np.log(mfcc_spoof_train.shape[0])+g2_adapt.score(X_test)).astype('int')\n",
    "    accuracy = np.mean(prediction == y_test) * 100\n",
    "    print accuracy\n",
    "    acc.append(accuracy)\n",
    "    \n",
    "print np.max(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def devideData(X,y):\n",
    "    kf = StratifiedKFold( y, n_folds=5 )\n",
    "    first_indices, second_indices = next(iter(kf))\n",
    "    X_first, y_first = X[first_indices], y[first_indices]\n",
    "    X_second, y_second = X[second_indices], y[second_indices]\n",
    "    return X_first, y_first, X_second, y_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GMM(covariance_type='diag', init_params='wmc', min_covar=0.001,\n",
       "  n_components=200, n_init=1, n_iter=20, params='wmc', random_state=None,\n",
       "  thresh=None, tol=0.001, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GMM(n_components = 200, covariance_type='diag',init_params='wmc', n_iter=20)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_original = computeUBM(model, mfcc_original_develop)\n",
    "adapt_spoof = computeUBM(model, mfcc_spoof_develop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy - prediction on evaluation set 4.86236065438\n"
     ]
    }
   ],
   "source": [
    "prediction  = np.array(adapt_original.score(X_test)  < adapt_spoof.score(X_test)).astype('int')\n",
    "\n",
    "accuracy = np.mean(prediction == y_test) * 100\n",
    "print 'accuracy - prediction on evaluation set', accuracy"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
